{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import feather\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json(df):\n",
    "    json_columns = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    for column in json_columns:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [column+\".\"+subcolumn for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date and Time Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_processing(df):\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], format = '%Y%m%d')\n",
    "    df[\"_weekday\"] = df['date'].dt.weekday\n",
    "    df[\"_day\"] = df['date'].dt.day \n",
    "    df[\"_month\"] = df['date'].dt.month\n",
    "    df[\"_year\"] = df['date'].dt.year\n",
    "    df[\"_visitHour\"] = pd.to_datetime(df[\"visitStartTime\"], unit = \"s\").dt.hour\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Type Converions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_numeric_bool_fillna(df, is_test_set = False):\n",
    "    df[\"totals.visits\"] = df[\"totals.visits\"].astype(int)\n",
    "    df[\"totals.hits\"] = df[\"totals.hits\"].astype(int)\n",
    "    df[\"totals.pageviews\"].fillna(1, inplace = True)\n",
    "    df[\"totals.pageviews\"] = df[\"totals.pageviews\"].astype(int)\n",
    "    df[\"totals.bounces\"].fillna(0, inplace=True)\n",
    "    df[\"totals.bounces\"] = df[\"totals.bounces\"].astype(int)\n",
    "    df[\"totals.newVisits\"].fillna(0, inplace=True)\n",
    "    df[\"totals.newVisits\"] = df[\"totals.newVisits\"].astype(int)\n",
    "    df[\"trafficSource.isTrueDirect\"].fillna(False, inplace = True)\n",
    "    df['trafficSource.adwordsClickInfo.isVideoAd'].fillna(True, inplace = True)\n",
    "    df['totals.timeOnSite'].fillna(df['totals.timeOnSite'].median(skipna = True), inplace = True)\n",
    "    df['totals.timeOnSite'] = df['totals.timeOnSite'].astype(int)\n",
    "    df[\"totals.transactionRevenue\"].fillna(0.0, inplace=True)\n",
    "    df[\"totals.transactionRevenue\"] = df[\"totals.transactionRevenue\"].astype(float)\n",
    "    if is_test_set:\n",
    "        df[\"totals.totalTransactionRevenue\"].fillna(0.0, inplace=True)\n",
    "        df[\"totals.totalTransactionRevenue\"] = df[\"totals.totalTransactionRevenue\"].astype(float)\n",
    "        df[\"totals.transactions\"].fillna(0, inplace=True)\n",
    "        df[\"totals.transactions\"] = df[\"totals.transactions\"].astype(int)\n",
    "        return df\n",
    "    else:\n",
    "        #df[\"totals.transactionRevenue\"].fillna(0.0, inplace=True)\n",
    "        #df[\"totals.transactionRevenue\"] = df[\"totals.transactionRevenue\"].astype(float)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably only need to log normalise the transaction revenue, but will create a function anyway, just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_normalise(df, is_test_set):\n",
    "        df[\"totals.transactionRevenue\"] = df[\"totals.transactionRevenue\"].apply(lambda x: np.log1p(x))\n",
    "        df[\"totals.totalTransactionRevenue\"] = df[\"totals.totalTransactionRevenue\"].apply(lambda x: np.log1p(x))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Columns and hits column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_remove_cols(df, cols_to_drop = []):\n",
    "    if cols_to_drop == []:\n",
    "        constant_cols = [col for col in df.columns if df[col].nunique() == 1 and col != \"totals.visits\"]\n",
    "        null_cols =  [col for col in df.columns if df[col].isnull().sum()/len(df) > 0.5] \n",
    "        cols_to_drop = constant_cols + null_cols + ['hits','customDimensions']\n",
    "        df.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "        return df, cols_to_drop\n",
    "    else:\n",
    "        intersection = set(df.columns.tolist()).intersection(cols_to_drop)\n",
    "        df.drop(intersection, axis = 1, inplace = True)\n",
    "        return df, cols_to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flagging visitor ids as spenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_flag_spender(df):\n",
    "    im_df = pd.DataFrame(df.groupby('fullVisitorId', as_index = False)['totals.transactionRevenue'].sum())\n",
    "    im_df.columns = ['fullVisitorId', 'totals.totalTransactionRevenue']\n",
    "    im_df['spender'] = np.where(im_df['totals.totalTransactionRevenue']>0.0,True,False)\n",
    "    df = df.merge(im_df, on = 'fullVisitorId')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_df(df, output_file_name):\n",
    "    feather.write_dataframe(df, output_file_name)\n",
    "    feather.write_dataframe(df.sample(frac=0.1, random_state = 1), output_file_name.split('.')[0]+\"_sample.\"+output_file_name.split('.')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining PreProcessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df, is_test_set, cols_to_drop = []):\n",
    "    \n",
    "    df = convert_json(df)\n",
    "    \n",
    "    df = date_processing(df)\n",
    "    df = df_numeric_bool_fillna(df, is_test_set)\n",
    "    \n",
    "    df = df_normalise(df, is_test_set)\n",
    "    \n",
    "    df, cols_to_drop = df_remove_cols(df, cols_to_drop)\n",
    "    \n",
    "    return df, cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_load(raw_file_name, output_file_name, chunksize, is_test_set = False, cols_to_drop = []):\n",
    "    \n",
    "    df_proc = pd.DataFrame()\n",
    "    json_columns = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    df_reader = pd.read_csv(raw_file_name, converters = {column: json.loads for column in json_columns}, dtype = {'fullVisitorId':'str'}, chunksize = chunksize)\n",
    "    #chunksize works at 100,000. Smaller and not all the columns turn up in the json. \n",
    "    #probably a way to fix that later\n",
    "    \n",
    "    for chunk_id, df in enumerate(df_reader):\n",
    "        df.reset_index(drop=True, inplace=True) \n",
    "        df, cols_to_drop = process(df, is_test_set, cols_to_drop)\n",
    "        \n",
    "        df_proc = pd.concat([df_proc, df], axis = 0, sort=False).reset_index(drop=True)\n",
    "        \n",
    "        del df\n",
    "        \n",
    "        if chunk_id % 5 == 0:\n",
    "            print('{}: rows loaded: {}'.format(chunk_id, df_proc.shape[0]))\n",
    "\n",
    "    if is_test_set:\n",
    "        output_df(df_proc, output_file_name)\n",
    "        return df_proc\n",
    "    else:\n",
    "        df_proc = df_flag_spender(df_proc)\n",
    "        output_df(df_proc, output_file_name)\n",
    "        pickle.dump(cols_to_drop, open('data/cols_to_drop.pickle', 'wb'))\n",
    "        return df_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: rows loaded: 100000\n",
      "5: rows loaded: 600000\n",
      "10: rows loaded: 1100000\n",
      "15: rows loaded: 1600000\n",
      "Wall time: 10min 4s\n"
     ]
    }
   ],
   "source": [
    "%time clean_train_df = df_load('data/train_v2.csv', 'data/clean_train_v2.feather', chunksize = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = pickle.load(open('data/cols_to_drop_v2.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: rows loaded: 100000\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop = pickle.load(open('data/cols_to_drop_v2.pickle', 'rb'))\n",
    "clean_test_df = df_load('data/test_v2.csv', 'data/clean_test_v2.feather', chunksize = 100000, is_test_set = True, cols_to_drop = cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_train_df = feather.read_dataframe('data/clean_train_v2.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cheating a bit with choosing a large enough chunksize to avoid the issue of the json columns not having every column in each chunk. \n",
    "Instead of having null values they just aren't in the json, possibly will need to come back and deal with that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channelGrouping 8\n",
      "fullVisitorId 1323730\n",
      "device.browser 129\n",
      "device.operatingSystem 24\n",
      "device.deviceCategory 3\n",
      "geoNetwork.continent 6\n",
      "geoNetwork.subContinent 23\n",
      "geoNetwork.country 228\n",
      "geoNetwork.region 483\n",
      "geoNetwork.metro 123\n",
      "geoNetwork.city 956\n",
      "geoNetwork.networkDomain 41982\n",
      "trafficSource.campaign 33\n",
      "trafficSource.source 345\n",
      "trafficSource.medium 7\n",
      "trafficSource.campaignCode 1\n"
     ]
    }
   ],
   "source": [
    "for column in clean_train_df.select_dtypes(include = 'object').columns.tolist():\n",
    "    print(column + ' ' + str(clean_train_df[column].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chrome               0.686665\n",
       "Safari               0.182730\n",
       "Firefox              0.037373\n",
       "Internet Explorer    0.020765\n",
       "Android Webview      0.020058\n",
       "Edge                 0.012025\n",
       "Samsung Internet     0.009244\n",
       "Opera Mini           0.008791\n",
       "Safari (in-app)      0.008316\n",
       "Opera                0.005611\n",
       "Name: device.browser, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clean_train_df['device.browser'].value_counts()/clean_train_df['device.browser'].value_counts().sum()).head(10)\n",
    "#top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chrome               0.901858\n",
       "Safari               0.065356\n",
       "Firefox              0.018310\n",
       "Internet Explorer    0.007994\n",
       "Edge                 0.003997\n",
       "Opera                0.000756\n",
       "Safari (in-app)      0.000648\n",
       "Android Webview      0.000540\n",
       "Samsung Internet     0.000432\n",
       "YaBrowser            0.000054\n",
       "Amazon Silk          0.000054\n",
       "Name: device.browser, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_df.loc[clean_train_df['totals.transactionRevenue']>0]['device.browser'].value_counts()\\\n",
    "/clean_train_df.loc[clean_train_df['totals.transactionRevenue']>0]['device.browser'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chrome accounts for 68% overall, but 95% of spend. Will create group outside top 10 into other and then 1 hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Windows          619720\n",
       "Macintosh        438514\n",
       "Android          299386\n",
       "iOS              219334\n",
       "Linux             63971\n",
       "Chrome OS         51318\n",
       "(not set)         11815\n",
       "Windows Phone      1675\n",
       "Name: device.operatingSystem, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_df['device.operatingSystem'].value_counts().head(8)\n",
    "#top 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States     41.983344\n",
       "India              6.164884\n",
       "United Kingdom     4.293122\n",
       "Canada             2.988696\n",
       "Germany            2.254590\n",
       "Japan              2.144600\n",
       "Brazil             2.074064\n",
       "Vietnam            2.041108\n",
       "France             1.890084\n",
       "Thailand           1.747840\n",
       "Turkey             1.707274\n",
       "Taiwan             1.554728\n",
       "Mexico             1.479216\n",
       "Australia          1.384973\n",
       "Spain              1.371568\n",
       "Netherlands        1.296348\n",
       "Italy              1.211353\n",
       "Russia             1.149715\n",
       "Indonesia          0.976095\n",
       "Poland             0.929208\n",
       "Name: geoNetwork.country, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100*clean_train_df['geoNetwork.country'].value_counts()/clean_train_df['geoNetwork.country'].value_counts().sum()).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States    0.953765\n",
       "Canada           0.017014\n",
       "Venezuela        0.003673\n",
       "Taiwan           0.001728\n",
       "Mexico           0.001458\n",
       "Name: geoNetwork.country, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clean_train_df.loc[clean_train_df['totals.transactionRevenue']>0]['geoNetwork.country'].value_counts()\\\n",
    "/clean_train_df.loc[clean_train_df['totals.transactionRevenue']>0]['geoNetwork.country'].value_counts().sum()).head()\n",
    "#95% of Spend in the US. Will create a US vs Not US column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not available in demo dataset    0.384466\n",
       "California                       0.304904\n",
       "New York                         0.129794\n",
       "Illinois                         0.035811\n",
       "Washington                       0.027655\n",
       "Name: geoNetwork.region, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clean_train_df.loc[clean_train_df['totals.transactionRevenue']>0]['geoNetwork.region'].value_counts()\\\n",
    "/clean_train_df.loc[clean_train_df['totals.transactionRevenue']>0]['geoNetwork.region'].value_counts().sum()).head()\n",
    "#will drop for first pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not available in demo dataset    0.384466\n",
       "New York                         0.129686\n",
       "Mountain View                    0.111591\n",
       "San Francisco                    0.061467\n",
       "Sunnyvale                        0.045803\n",
       "Name: geoNetwork.city, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clean_train_df.loc[clean_train_df['totals.transactionRevenue']>0]['geoNetwork.city'].value_counts()\\\n",
    "/clean_train_df.loc[clean_train_df['totals.transactionRevenue']>0]['geoNetwork.city'].value_counts().sum()).head()\n",
    "#will drop for first pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Northern America    0.970779\n",
       "South America       0.006590\n",
       "Eastern Asia        0.004483\n",
       "Southeast Asia      0.003187\n",
       "Western Europe      0.002593\n",
       "Name: geoNetwork.subContinent, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clean_train_df.loc[clean_train_df['totals.transactionRevenue']>0]['geoNetwork.subContinent'].value_counts()\\\n",
    "/clean_train_df.loc[clean_train_df['totals.transactionRevenue']>0]['geoNetwork.subContinent'].value_counts().sum()).head()\n",
    "#Will Keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(not set)          499049\n",
       "unknown.unknown    269796\n",
       "comcast.net         55486\n",
       "rr.com              28715\n",
       "verizon.net         26547\n",
       "Name: geoNetwork.networkDomain, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_df['geoNetwork.networkDomain'].value_counts().head()\n",
    "#willdrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(not set)                                                 1604526\n",
       "Data Share Promo                                            32914\n",
       "1000557 | GA | US | en | Hybrid | GDN Text+Banner | AS      24410\n",
       "1000557 | GA | US | en | Hybrid | GDN Remarketing           15149\n",
       "AW - Dynamic Search Ads Whole Site                          15146\n",
       "Name: trafficSource.campaign, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_df['trafficSource.campaign'].value_counts().head()\n",
    "#will drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "organic      591783\n",
       "(none)       565957\n",
       "referral     432963\n",
       "cpc           75603\n",
       "affiliate     32915\n",
       "cpm            8982\n",
       "(not set)       134\n",
       "Name: trafficSource.medium, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_df['trafficSource.medium'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_df['US'] = np.where(clean_train_df['geoNetwork.country'] == 'United States',1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_not_top10 = clean_train_df.groupby('device.browser').count().sort_values('date', ascending = False).index[10:]\n",
    "clean_train_df['device.browser'].replace(device_not_top10, 'Other', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_not_top10 = clean_train_df.groupby('device.operatingSystem').count().sort_values('date', ascending = False).index[10:]\n",
    "clean_train_df['device.operatingSystem'].replace(os_not_top10, 'Other', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_prepped_df = pd.concat([clean_train_df, \\\n",
    "                             pd.get_dummies(clean_train_df[['channelGrouping', 'device.browser', 'device.operatingSystem', 'geoNetwork.subContinent', 'trafficSource.medium']])]\\\n",
    "                             , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols_to_drop = [column for column in clean_train_df.select_dtypes(include = 'object').columns.tolist() if column != 'fullVisitorId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_prepped_df.drop(cat_cols_to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feather.write_dataframe(clean_prepped_df, 'data/encode_train_v2.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_df = feather.read_dataframe('data/clean_test_v2.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_df['US'] = np.where(clean_test_df['geoNetwork.country'] == 'United States',1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_train_values = [value for value in clean_train_df['device.browser'].unique() if value != 'Other']\n",
    "clean_test_df['device.browser'] = np.where(clean_test_df['device.browser'].isin(device_train_values), clean_test_df['device.browser'], 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_train_values = [value for value in clean_train_df['device.operatingSystem'].unique() if value != 'Other']\n",
    "clean_test_df['device.operatingSystem'] = np.where(clean_test_df['device.operatingSystem'].isin(os_train_values), clean_test_df['device.operatingSystem'], 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_prepped_test_df = pd.concat([clean_test_df, \\\n",
    "                             pd.get_dummies(clean_test_df[['channelGrouping', 'device.browser', 'device.operatingSystem', 'geoNetwork.subContinent', 'trafficSource.medium']])]\\\n",
    "                             , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['geoNetwork.networkDomain',\n",
       " 'geoNetwork.metro',\n",
       " 'device.deviceCategory',\n",
       " 'geoNetwork.country',\n",
       " 'device.browser',\n",
       " 'geoNetwork.region',\n",
       " 'geoNetwork.continent',\n",
       " 'geoNetwork.city',\n",
       " 'trafficSource.source',\n",
       " 'trafficSource.medium',\n",
       " 'channelGrouping',\n",
       " 'trafficSource.campaign',\n",
       " 'geoNetwork.subContinent',\n",
       " 'device.operatingSystem']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(clean_prepped_test_df.columns.tolist()).intersection(cat_cols_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_prepped_test_df.drop(list(set(clean_prepped_test_df.columns.tolist()).intersection(cat_cols_to_drop)), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spender']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[column for column in clean_prepped_df.columns if column not in clean_prepped_test_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['totals.sessionQualityDim', 'totals.transactions']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[column for column in clean_prepped_test_df.columns if column not in clean_prepped_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_prepped_test_df.drop([column for column in clean_prepped_test_df.columns if column not in clean_prepped_df.columns], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "feather.write_dataframe(clean_prepped_test_df, 'data/encode_test_v2.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
